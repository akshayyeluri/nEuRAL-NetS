{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores to use:  4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, json\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "import transforms as t\n",
    "import classifiers as clsf\n",
    "\n",
    "import multiprocessing\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f'Number of cores to use: ', n_cores)\n",
    "\n",
    "np.random.seed(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df0 = pd.read_csv('train.csv')\n",
    "# Y0 are new labels (maybe smoothed or with regression), Y_c0 are original class labels\n",
    "X0_df, Y_c0, Y0 = t.transform_df(train_df0, train=True, as_df=True, k=None)\n",
    "X0 = X0_df.values.astype(np.float32)\n",
    "Y_c0, Y0 = Y_c0.astype(np.int64), Y0.astype(np.int64)\n",
    "(N, D) = X0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_inds = t.get_group_inds(X0_df) # This will normalize all prices together, and all vols\n",
    "#group_inds = [] # This will normalize each feature separately\n",
    "def get_pars(X):\n",
    "    return t.get_pars_for_processing(X, group_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6421\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6370\u001b[0m  1.6783\n",
      "      2        \u001b[36m0.6353\u001b[0m       \u001b[32m0.6476\u001b[0m        \u001b[35m0.6354\u001b[0m  1.6941\n",
      "      3        \u001b[36m0.6319\u001b[0m       \u001b[32m0.6480\u001b[0m        \u001b[35m0.6316\u001b[0m  1.8798\n",
      "Tuning NN ...\n",
      "Re-initializing module because the following parameters were re-set: drop, hidden, nFeat.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: drop, hidden, nFeat.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6540\u001b[0m       \u001b[32m0.6449\u001b[0m        \u001b[35m0.6448\u001b[0m  1.7386\n",
      "      2        \u001b[36m0.6455\u001b[0m       0.6448        \u001b[35m0.6415\u001b[0m  1.8781\n",
      "Tuned in: 171.2130479812622\n",
      "{'lr': 0.01, 'max_epochs': 2, 'module__drop': 0.4, 'module__hidden': 20}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Type</th>\n",
       "      <th>Tuning</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>test</td>\n",
       "      <td>base</td>\n",
       "      <td>0.641367</td>\n",
       "      <td>0.630645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN</td>\n",
       "      <td>test</td>\n",
       "      <td>tuned</td>\n",
       "      <td>0.634884</td>\n",
       "      <td>0.609587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Type Tuning  Accuracy       AUC\n",
       "1         NN  test   base  0.641367  0.630645\n",
       "3         NN  test  tuned  0.634884  0.609587"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Just gonna take a random 10th for validation\n",
    "X, valX, Y, valY = train_test_split(X0, Y0, shuffle=True, test_size=0.1)\n",
    "pars = get_pars(X)\n",
    "X, valX = t.process_with_pars(X, pars), t.process_with_pars(valX, pars)\n",
    "\n",
    "frac = 1 / 4\n",
    "t_size, v_size = int(X.shape[0] * frac), int(valX.shape[0] * frac)\n",
    "train_res, test_res, models = clsf.TuneClassifiers(X[:t_size], valX[:v_size], Y[:t_size], valY[:v_size], \\\n",
    "                                                   algs=['NN'], nFeat=D)\n",
    "test_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res_dict = {}\n",
    "for name, model in models.items():\n",
    "    info_dict = model.cv_results_\n",
    "    s = list(zip(info_dict['params'],\\\n",
    "                 info_dict['mean_test_score'],\\\n",
    "                 info_dict['std_test_score']))\n",
    "    s = sorted(s, key=lambda x: x[1], reverse=True) # Sort by mean test_score\n",
    "    cv_res_dict[name] = s\n",
    "\n",
    "gName = 'grid_search.json'\n",
    "with open(gName, 'w') as f:\n",
    "    json.dump(cv_res_dict, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV fold: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6491\u001b[0m       \u001b[32m0.6431\u001b[0m        \u001b[35m0.6445\u001b[0m  7.8253\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6489\u001b[0m       \u001b[32m0.6435\u001b[0m        \u001b[35m0.6431\u001b[0m  7.5969\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6491\u001b[0m       \u001b[32m0.6437\u001b[0m        \u001b[35m0.6443\u001b[0m  7.1470\n",
      "      2        \u001b[36m0.6414\u001b[0m       \u001b[32m0.6435\u001b[0m        \u001b[35m0.6381\u001b[0m  6.9375\n",
      "      2        \u001b[36m0.6411\u001b[0m       0.6434        \u001b[35m0.6380\u001b[0m  6.8446\n",
      "      2        \u001b[36m0.6418\u001b[0m       \u001b[32m0.6440\u001b[0m        \u001b[35m0.6383\u001b[0m  6.9132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV fold: 3it [00:23,  7.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6153201007708898, 0.6434501502413991)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = RandomForestClassifier(**models['RF'].best_params_)\n",
    "#clf = AdaBoostClassifier(**models['ADB'].best_params_)\n",
    "#clf = GradientBoostingClassifier(**models['GDB'].best_params_)\n",
    "#clf = GradientBoostingClassifier(**models['GDB'].best_params_)\n",
    "clf = NeuralNetClassifier(clsf.NNModel, **models['NN'].best_params_,\\\n",
    "                          iterator_train__shuffle=True, module__nFeat=D)\n",
    "aucs, accs = clsf.cross_val(clf, X0, Y0, (get_pars, t.process_with_pars))\n",
    "aucs.mean(), accs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6469\u001b[0m       \u001b[32m0.6437\u001b[0m        \u001b[35m0.6397\u001b[0m  9.2470\n",
      "      2        \u001b[36m0.6388\u001b[0m       \u001b[32m0.6440\u001b[0m        \u001b[35m0.6352\u001b[0m  9.0776\n"
     ]
    }
   ],
   "source": [
    "# Maybe parallelize\n",
    "if 'n_jobs' in clf.get_params():\n",
    "    clf.set_params(n_jobs=n_cores)\n",
    "\n",
    "pars = get_pars(X0)\n",
    "process = lambda x: t.process_with_pars(x, pars).astype(np.float32)\n",
    "X = process(X0)\n",
    "clf.fit(X, Y0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = datetime.today().strftime('%y%m%d_%H%M') + \"_model.pkl\"\n",
    "\n",
    "with open(fName, 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open(fName, 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_dict = {}\n",
    "if hasattr(clf, 'feature_importance_'):\n",
    "    inds = np.array(sorted(range(len(X0_df.columns)), \\\n",
    "                           key=lambda x: clf.feature_importances_[x], \\\n",
    "                           reverse=True))\n",
    "    imp_dict = dict(zip(X0_df.columns[inds], clf.feature_importances_[inds]))\n",
    "imp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final train performance (on original labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6207880074644534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(Y_c0, clf.predict_proba(X)[:,1]) # Get auc on original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436949255545427"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.predict(X) == Y0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df0 = pd.read_csv('test.csv')\n",
    "tX = t.transform_df(test_df0)\n",
    "tX = process(tX)\n",
    "\n",
    "output = clf.predict_proba(tX)[:, 1]\n",
    "     \n",
    "output_df = pd.DataFrame({'id':test_df0['id'], 'Predicted': output})\n",
    "output_df.to_csv(f\"submission_{datetime.today().strftime('%y%m%d_%H%M')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks on output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of train_labels: 0.3569583713157095\n",
      "mean of train_preds: 0.6232185959815979\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert(np.all((0 <= output) & (output <= 1)))\n",
    "print(f'mean of train_labels: {np.mean(Y_c0)}')\n",
    "print(f'mean of train_preds: {np.mean(output)}')\n",
    "plt.hist(output);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random code scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Garbage Beyond!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b3d7f98920aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Garbage Beyond!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Garbage Beyond!"
     ]
    }
   ],
   "source": [
    "raise ValueError('Garbage Beyond!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parFName = 'best_pars.pars'\n",
    "with open(parFName, 'rb') as f:\n",
    "    best_pars = pickle.load(f)\n",
    "    \n",
    "best_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = get_pars(X0)\n",
    "process = lambda x: t.process_with_pars(x, pars)\n",
    "reps = 4\n",
    "\n",
    "for clf in tqdm.tqdm_notebook([RandomForestClassifier(max_features=0.3, min_samples_leaf=100, n_estimators=150),\n",
    "            RandomForestClassifier(max_features=0.4, min_samples_leaf=80, n_estimators=150),\n",
    "            RandomForestClassifier(max_features=0.5, min_samples_leaf=50, n_estimators=150)] * reps):\n",
    "    # Maybe parallelize\n",
    "    if 'n_jobs' in clf.get_params():\n",
    "        clf.set_params(n_jobs=n_cores)\n",
    "    X = process(X0)\n",
    "    clf.fit(X, Y0)\n",
    "    fName = datetime.today().strftime('%y%m%d_%H%M') + \"_model.pkl\"\n",
    "    with open(fName, 'wb') as f:\n",
    "        pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
