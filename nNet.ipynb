{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as tdata\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import helpers as h\n",
    "import models as clsf\n",
    "\n",
    "np.random.seed(69)\n",
    "torch.manual_seed(69);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df0 = pd.read_csv('train.csv')\n",
    "X0, Y_c0, Y0 = h.transform_df(train_df0, train=True)\n",
    "(N, d) = X0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Just gonna take a random 10th for validation\n",
    "X, valX, Y_c, valY_c, Y, valY = train_test_split(X0, Y_c0, Y0, test_size=0.1)\n",
    "\n",
    "pars = h.get_pars_for_processing(X)\n",
    "X, valX = h.process_with_pars(X, pars), h.process_with_pars(valX, pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "X, Y = torch.Tensor(X), torch.Tensor(Y)\n",
    "valX, valY = torch.Tensor(valX), torch.Tensor(valY)\n",
    "\n",
    "\n",
    "train_loader = tdata.DataLoader(tdata.TensorDataset(X, Y), \\\n",
    "                                     batch_size=batch_size,\\\n",
    "                                     shuffle=True)\n",
    "val_loader = tdata.DataLoader(tdata.TensorDataset(valX, valY), \\\n",
    "                                     batch_size=batch_size,\\\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on sigmoid\n",
    "Either Option 1:\n",
    "\n",
    "1) No nn.Sigmoid() layer, 2) Use nn.BCEWithLogitsLoss, and 3) apply torch.sigmoid() to output to\n",
    "get probabilities.\n",
    "This option is more numerically stable\n",
    "\n",
    "OR Option 2:\n",
    "\n",
    "1) Use nn.Sigmoid() layer, 2) Use nn.BCELoss(), and 3) Don't need torch.sigmoid() at the prediction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple one hidden layer (k units) logistic regression\n",
    "k = 128\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(X.shape[1], k),\n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(k, 1),\n",
    "        #nn.Sigmoid(); #Option 2\n",
    "    )\n",
    "\n",
    "#criterion = nn.MSELoss() # Do regression\n",
    "criterion = nn.BCEWithLogitsLoss(); #Option 1\n",
    "#criterion = nn.BCELoss(); #Option 2\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some layers, such as Dropout, behave differently during training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(4):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Erase accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss (broadcast target to (B, 1), where B is batch size)\n",
    "        loss = criterion(output, target.unsqueeze(1)) \n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Track loss each epoch\n",
    "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))\n",
    "    print(model(X).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting layers like Dropout into evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def acc(valY_c, output):\n",
    "    return sum(np.round(output) == valY_c) / len(valY_c)\n",
    "    #return sum(valY_c == ((np.sign(output) + 1) / 2)) / len(valY_c)\n",
    "\n",
    "# Turning off automatic differentiation\n",
    "with torch.no_grad():\n",
    "    output = torch.sigmoid(model(valX)).data.numpy().squeeze()\n",
    "    #output = h.scale(output)\n",
    "    print('Auroc on val set: ', auc(valY_c, output))\n",
    "    print('Accuracy: ', acc(valY_c, output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df0 = pd.read_csv('test.csv')\n",
    "tX = h.transform_df(test_df0)\n",
    "tX = h.process_with_pars(tX, pars)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = torch.sigmoid(model(torch.Tensor(tX))).data.numpy().squeeze()\n",
    "    #output = h.scale(output)\n",
    "    #output = model(torch.Tensor(tX)); #Option 2\n",
    "     \n",
    "output_df = pd.DataFrame({'id':test_df0['id'], 'Predicted': output})\n",
    "output_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some data to make sure logistic regression worked lmao\n",
    "import sys\n",
    "sys.path.append('~/git/MLModels')\n",
    "from MLModels import utils as u\n",
    "from MLModels import linearModels as lm\n",
    "\n",
    "f, line = u.genF(zero_one=True)\n",
    "X, Y = u.genData(f, 10000)\n",
    "(N, D) = X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "neural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
